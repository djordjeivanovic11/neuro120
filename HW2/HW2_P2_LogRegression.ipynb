{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8wL0tuqdq5f"
   },
   "source": [
    "# HW 2 Problem 2: Logistic Regression\n",
    "\n",
    "In this problem, you will build a decoding model that predicts the orientation of a visual stimulus based on neural activity.\n",
    "\n",
    "The data come from experiments in which monkeys viewed static gratings of different orientations while the lab recorded activity of multiple single neurons in **primary visual cortex (V1)** using chronically implanted tetrode arrays.\n",
    "\n",
    "The gratings were presented at 7 different orientations and two different contrasts (10% and 100%). Each grating was presented for 500 ms. This figure gives a sense of what a grating looks like and how orientation can vary (top row) and how contrast can vary (bottom row). </br></br>\n",
    "![grating stimulus examples](grating_stimuli.jpg)\n",
    "</br></br>\n",
    "Bethge et al. published a classic paper investigating the population code of these visual neurons using decoding analyses. We will implement similar analyses to what they did in this article: https://www.jneurosci.org/content/32/31/10618.short. Data publicly available from the Bethge lab [here](http://bethgelab.org/datasets/v1gratings/).\n",
    "</br></br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NBTtJY8p4Yh"
   },
   "source": [
    "## Load in the data (100% contrast condition only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kCgHCEPo6Hn_"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1738354573342,
     "user": {
      "displayName": "Kristina Penikis",
      "userId": "11146911841924357157"
     },
     "user_tz": 300
    },
    "id": "s0ZcdUUM6HoC",
    "outputId": "5bb9eada-8989-4167-fcfe-1e424bf10c2d"
   },
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "data = sio.loadmat('spks.mat')\n",
    "\n",
    "spikes = data['spk']\n",
    "ori = data['ori'].reshape((-1,))\n",
    "timevec = data['times'].reshape((-1,))\n",
    "\n",
    "print('spikes: ' + str(np.shape(spikes)))\n",
    "print('ori: ' + str(np.shape(ori)))\n",
    "print('timevec: ' + str(np.shape(timevec)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ilhStIL6HoD"
   },
   "source": [
    "**`spikes`**: contains the spike counts binned into 10 ms bins. The dimensions are (neurons x orientations x time bins x trials).\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Note that spikes is binned spikes over time, not a single response value per orientation.\n",
    "\n",
    "**`ori`**: contains the 7 different orientations used (corresponding to the second dimension in spikes)\n",
    "\n",
    "**`timevec`**: contains the time of each 10 ms time bin relative to when the grating was presented (grating presentation happened at 0 ms). times reflect the middle of each time bin.\n",
    "\n",
    "<br><br>\n",
    "**Explore the data**\n",
    "\n",
    "Let's plot the average spike counts over time for neuron 1 at various orientiations.\n",
    "\n",
    "Change the variable `i_ori` to view responses to different stimuli.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZJ_zp686HoD",
    "outputId": "f7daa1f1-71bd-4c13-8ff7-42c862874580"
   },
   "outputs": [],
   "source": [
    "i_ori = 0   # if you're used to matlab, remember python indexing begins at 0!\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(timevec, np.mean(spikes[0, i_ori, :, :], axis=1))\n",
    "_ = ax.set(xlabel='Time (ms)',\n",
    "        ylabel = 'Mean spike count',\n",
    "        title=f'orientation = {ori[i_ori]}');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8AP3hu9i6HoE"
   },
   "source": [
    "\n",
    "# I. Decoding orientation at a single time bin\n",
    "\n",
    "First, we will decode the orientation of the grating from the neural activities that occur in the bin from 190 ms to 200 ms after the grating is presented. We will use a logistic regression model because the output variable is categorical in this case -- we will predict which of the 7 distinct orientations was presented.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDJqH6PY6HoE"
   },
   "source": [
    "\n",
    "## Preparing the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qfBIVpm6HoF"
   },
   "source": [
    "Grab the spiking data in the correct time bin after the grating presentation.  Remember, the time bin from 190-200 ms corresponds to the entry in timevec equal to 195 ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1738354574360,
     "user": {
      "displayName": "Kristina Penikis",
      "userId": "11146911841924357157"
     },
     "user_tz": 300
    },
    "id": "66_JM9Hb6HoF",
    "outputId": "cc3bf9d1-b1a4-4827-8faa-8c85228a0045"
   },
   "outputs": [],
   "source": [
    "# print(timevec)\n",
    "bin_index = np.where(timevec == 195)[0][0]\n",
    "\n",
    "spikes_t195 = spikes[:, :, bin_index, :]\n",
    "print(f'The shape of spikes_t195 is {spikes_t195.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jT2CNAXX6HoH"
   },
   "source": [
    "<br>Now let's divide the data into train and test trials. We have 85 trials per orientation. We want to divide them randomly and use 80% for training the model and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aQtV1FH26HoH",
    "outputId": "7bf87e18-3079-44fe-df2f-4cbb67fb6054"
   },
   "outputs": [],
   "source": [
    "n_neurons = spikes.shape[0]\n",
    "n_trials = spikes.shape[3]\n",
    "n_train_trials = int(0.8*n_trials)\n",
    "n_test_trials = n_trials - n_train_trials\n",
    "\n",
    "# Get random trials for train vs test\n",
    "np.random.seed(0) # I'm adding this line so we all arrive at the same answer. In real analyses, you \n",
    "                  # would want trial allocation to be truly random.\n",
    "trials = np.arange(0, n_trials)\n",
    "np.random.shuffle(trials)\n",
    "train_trials = trials[:n_train_trials]\n",
    "test_trials = trials[n_train_trials:]\n",
    "\n",
    "print(f'The train trials are {train_trials}')\n",
    "print(f'\\nThe test trials are {test_trials}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6gt16Tw6HoI"
   },
   "source": [
    "<br>\n",
    "Now we separate the spiking data on the train and test trials.\n",
    "\n",
    "We will also reshape the arrays to combine orientation and trial into a single dimension. Now, each combo of orientation and trial is one data point. \n",
    "\n",
    "We'll create a corresponding array of the orientation on each trial, in accordance with how we reshaped the spikes array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jEFPL_iP6HoI"
   },
   "outputs": [],
   "source": [
    "spikes_train = spikes_t195[:, :, train_trials].reshape((n_neurons, -1,)) # input data\n",
    "ori_train = np.repeat(ori, n_train_trials)  # output data: correct label\n",
    "# print(spikes_train.shape)\n",
    "# print(ori_train.shape)\n",
    "\n",
    "spikes_test = spikes_t195[:, :, test_trials].reshape((n_neurons, -1,)) # input data\n",
    "ori_test = np.repeat(ori, n_test_trials)  # output data: correct label\n",
    "# print(spikes_test.shape)\n",
    "# print(ori_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RufRbxQOFlQV"
   },
   "source": [
    "### Problem 2a: comprehension check\n",
    "Why does the `spikes_test` array have 119 columns?\n",
    "</br></br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KlTYKDTGh8RG"
   },
   "source": [
    "<font color=#2AAA8A><span style=\"font-size:larger;\">\n",
    "**Answer**\n",
    "\n",
    "<font color=#2AAA8A><span style=\"font-size:larger;\">\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4482I826HoI"
   },
   "source": [
    "\n",
    "## Fitting the logistic regression model\n",
    "\n",
    "To fit the logistic regression model, we will use sklearn's LogisticRegression functionality. Read about it here: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "The first step is to define our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mNv1MTM56HoI"
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYf73GrK6HoJ"
   },
   "source": [
    "### Problem 2b (coding): Fitting a logistic regression model\n",
    "Now we'll train the model to predict orientation from spike data by calling the fit method: `model.fit(inputs, outputs)`. `inputs` should be a 2D array where each row represents a single trial and each column represents a feature (each input variable will be weighted and combined in the logistic regression). `outputs` should be a 1D array containing the target values (orientations) for each trial, with length equal to the number of trials.\n",
    "\n",
    "Put in the correct arguments to `model.fit` to fit the logistic model to our training data.\n",
    "\n",
    "Hint: you can swap rows and columns in an array by transposing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "executionInfo": {
     "elapsed": 170,
     "status": "ok",
     "timestamp": 1738354574527,
     "user": {
      "displayName": "Kristina Penikis",
      "userId": "11146911841924357157"
     },
     "user_tz": 300
    },
    "id": "ph88Ne7P6HoJ",
    "outputId": "946de6bc-c82f-4f33-dc77-d92d2d39bd96"
   },
   "outputs": [],
   "source": [
    "# TODO: fill out the call to model.fit with the correct data \n",
    "model.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4-D3xXP6HoJ"
   },
   "source": [
    "### Problem 2c (coding): Evaluating the logistic regression model quantitatively\n",
    "\n",
    "After fitting the model, we want to assess how good its predictions are. We can use `model.score` to compute the accuracy of the model to evalute it's performance. Accuracy will be the percentage of the trials on which the model predicted the correct orientation. Crucially, we want to use our held-out test data to evaluate model success -- different data points than those used to train the model.\n",
    "\n",
    "Fill out the code below to compute the accuracy to evalute the logistic regression model's performance.\n",
    "The arguments to `model.score` should have the same format as `model.fit`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1738354574527,
     "user": {
      "displayName": "Kristina Penikis",
      "userId": "11146911841924357157"
     },
     "user_tz": 300
    },
    "id": "eRsG39RU6HoK",
    "outputId": "b511355f-4536-4124-ce5f-81101c1f7546"
   },
   "outputs": [],
   "source": [
    "# TODO: fill out the call to fit with the correct data\n",
    "accuracy = model.score(...)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wXkadgEC6HoK"
   },
   "source": [
    "### Problem 2d: Interpreting model results\n",
    "\n",
    "i) What does this accuracy score mean? State the result in plain English.\n",
    "\n",
    "ii) If there were no information about orientation in the neural activity, what accuracy would the model have? In other words, what would be the baseline chance of correctly guessing the stimulus orientation?\n",
    "\n",
    "iii) Does it seem like there's information about the orientation present in the neural activity 200 ms after grating presentation? Why or why not?\n",
    "\n",
    "iv) Is there overfitting happening? How do you find out? Demonstrate using code.\n",
    "\n",
    "v) If we had fewer trials overall (10 trials) and followed the same procedure, do you think the accuracy of the model on the training data would increase, decrease, or stay the same? How about the accuracy on the testing data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDJksQxhhw3b"
   },
   "source": [
    "<font color=#2AAA8A><span style=\"font-size:larger;\">\n",
    "**Answer**\n",
    "\n",
    "<font color=#2AAA8A><span style=\"font-size:larger;\">\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer to 2d iv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2olyi9fE6HoL"
   },
   "source": [
    "</br></br>\n",
    "### Problem 2e: Inspect model coefficients\n",
    "\n",
    "We can access the learned parameters of the model using `model.coef_`. In this case, the coefficients are in a 7 x 22 array representing the learned weights for all 22 neurons to the 7 orientations. You can plot the array `plt.imshow` to visualize these weights.\n",
    "\n",
    "**In general, what can be gleaned from inspecting the coefficients?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dVrSJrHajig8",
    "outputId": "3ebdd9e9-6d67-4a89-8b3e-a5a83577529c"
   },
   "outputs": [],
   "source": [
    "plt.imshow(model.coef_, aspect='auto')\n",
    "plt.xlabel('Neuron')\n",
    "plt.ylabel('Orientation')\n",
    "plt.title('Model Coefficients')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#2AAA8A><span style=\"font-size:larger;\">\n",
    "**Answer**\n",
    "\n",
    "<font color=#2AAA8A><span style=\"font-size:larger;\">\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPYjh5I_Gael"
   },
   "source": [
    " ðŸ’ª _almost there_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q620K4pi6HoL"
   },
   "source": [
    "# II. Decoding accuracy over time\n",
    "\n",
    "Now, instead of looking at a single time bin, we want to get a sense of the timescale at which orientation information can be read out from the neural population. Each grating stimulus was presented for 500 ms duration. How long after the grating is presented is there information about orientation present in the neural population?\n",
    "\n",
    "To investigate this, we can fit a logistic regression model for each time bin and calcualte the decoding accuracy for that time bin. We can then look at how the accuracy changes over time relative to the grating presentation onset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "daPLoXrg6HoM"
   },
   "source": [
    "### Problem 2f (coding): Decoding accuracy over time\n",
    "\n",
    "In the code above, you've already figured out how to fit and evaluate a logistic regression decoding model for a single time bin (the one corresponding to 195 ms after stimulus onset). Generalize that code to calculate the accuracy over time bin for all 90 time bins.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gx7NBX1J6HoM",
    "outputId": "38dc982b-bc7a-437b-dae2-50ad5b96c5cf"
   },
   "outputs": [],
   "source": [
    "n_time_bins = spikes.shape[2]\n",
    "accuracy = np.zeros((n_time_bins, ))\n",
    "\n",
    "# loop over time bins\n",
    "for i_bin in range(n_time_bins):\n",
    "\n",
    "    # TODO: fit a model and compute it's accuracy for the data in i_bin\n",
    "    ...\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "ax.plot(timevec, accuracy, '-o')\n",
    "_ = ax.set(xlabel='Time (ms)',\n",
    "       ylabel = 'Accuracy',\n",
    "       xticks=np.arange(-200, 800, 50))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6Q1gXCw6HoM"
   },
   "source": [
    "<br>You should see a plot that looks approximately like [this](https://drive.google.com/file/d/1SlJ0-6q7D_phXUXRBhrVlkD1v6xzwtOS/view?usp=sharing). There might be small differences depending on how train vs test trials were split.\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GScw-X276HoM"
   },
   "source": [
    "## Problem 2g: Interpreting this plot\n",
    "\n",
    "Please answer these questions for the correct plot linked above, even if you got a different one.\n",
    "\n",
    "i) About how long after the presentation of the grating (at time 0), does information about orientation appear in the neural population activity?\n",
    "\n",
    "ii) What might that time delay between stimulus presentation and information presence be due to?\n",
    "\n",
    "iii) Each stimulus was presented for 500 ms (from 0 to 500 ms). How does the amount of information about orientation change over time, compared to both the peak and chance accuracy levels?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#2AAA8A><span style=\"font-size:larger;\">\n",
    "**Answer**\n",
    "\n",
    "<font color=#2AAA8A><span style=\"font-size:larger;\">\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2h: Other scientific questions\n",
    "\n",
    "**Propose a scientific question about neural coding in V1 that you could address with this data set using decoding methods. Describe the approach for how you would answer this question.**\n",
    "\n",
    "Your answer should include: \n",
    "* **Research question** - It should include what specific aspect of neural coding youâ€™re investigating. (i.e. don't just ask \"can X be decoded from the data?\")\n",
    "* **Decoding approach** - What model will you use, logistric regression or something else? What will the input data consist of? What will you be comparing? \n",
    "* **Interpretation** - Suggest 2 feasible outcomes. What would each outcome imply about how V1 encodes visual information? \n",
    "\n",
    "The exercise only used data from the 100% contrast stimuli, but we also have data for the 10% contrast stimuli!\n",
    "\n",
    "If you want more info about the experimental details, look at the Bethge publication linked at the top of this page. \n",
    "\n",
    "_Avoid simply proposing to repeat the same question about time-course on 10% contrast data. Push yourself to ask a differe question about neural representation or computation!_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Example Answer for Problem 2h based on Part II of this assignment***\n",
    "\n",
    "**Research Question:** What is the timecourse of information about grating stimulus orientation contained in the V1 population? For example, how quickly does orientation information become decodable, and how long does it last?\n",
    "\n",
    "**Decoding Approach:** For each time bin, I would train a logistic regression classifier to decode the stimulus orientation from the population of V1 neurons recorded in this experiment. The input data for each would be an array of spike counts with shape of (n_neuron, n_trials). After calculating accuracy on held-out trials, I would plot accuracy as a function of time. \n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "Outcome 1: Information remains constantly above chance throughout stimulus duration. \n",
    "If decoding accuracy rose immediately at stimulus onset and remained at peak levels throughout the 500 ms stimulus presentation, returning to chance immediately at offset, this would suggest that V1 maintains equally strong orientation information about stimuli that are physically present in the visual field. An immediate return to chance would reveal that V1 represents only currently present visual information without any persistence.\n",
    "\n",
    "Outcome 2: Accuracy increases (with a small delay) after stimulus onset, peaks early, then declines but remains above chance. \n",
    "This outcome implies that the most information about orientation is available shortly after the stimulus appears. While some information about orientation remains in the population, the amount is less after that initial transient response. This pattern would suggest that perhaps adaptation mechanisms alter the population activity, and/or that the V1 population is most responsive to changes within the visual field.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#2AAA8A><span style=\"font-size:larger;\">\n",
    "**Answer**\n",
    "\n",
    "<font color=#2AAA8A><span style=\"font-size:larger;\">\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
