{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0J-rGdXB5_F"
   },
   "source": [
    "# HW 3 Problem 1: Investigating Mixed Selectivity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccMFHI8dB5_G"
   },
   "source": [
    "In this problem, we will be working with data from the [Hardcastle](https://www.cell.com/action/showPdf?pii=S0896-6273%2817%2930237-4) paper discussed in section. We will be implementing the LNP model described in this paper. Use the paper as a reference if needed.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vJUjZIu8B5_F"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1043,
     "status": "ok",
     "timestamp": 1739331493855,
     "user": {
      "displayName": "Kristina Penikis",
      "userId": "11146911841924357157"
     },
     "user_tz": 300
    },
    "id": "R-fDN4-FnMnS",
    "outputId": "3ca259d8-1764-467c-b4d3-083877c4dc4d"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "d = None\n",
    "d = sio.loadmat('data_for_cell77.mat')\n",
    "if d != None:\n",
    "  print('Data loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "We will focus on the activity of a single neuron recorded while a mouse wanders around an arena. **The binsize is already set to 20 ms; we won't be varying this parameter.**\n",
    "\n",
    "> `times` denotes the edges of each time bin\n",
    ">\n",
    "> `spikes` contains the number of spikes in each bin\n",
    "\n",
    "<br>To track the mouse's position within the arena, we use the x/y positions of two LEDs on the head of the mouse (one on the left, one on the right). The mouse's location is calculated as the position of the center point between the two LEDs.\n",
    "\n",
    "> `posx_c` is the x-position of the mouse's head\n",
    ">\n",
    "> `posy_c` is the y-position of the mouse's head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JnQ5IrSZB5_G"
   },
   "outputs": [],
   "source": [
    "bin_width = 0.02  # 20 ms\n",
    "times = d['post']\n",
    "times = np.append(times, times[-1] + bin_width)\n",
    "spikes = d['spiketrain'][:, 0]\n",
    "\n",
    "posx = d['posx'][:,0] # x-position of left LED every 20 ms\n",
    "posx2 = d['posx2'][:,0] # x-position of right LED every 20 ms\n",
    "posx_c = d['posx_c'][:, 0]  # x-position of mouse's head (middle of LEDs)\n",
    "\n",
    "posy = d['posy'][:,0] # y-position of left LED every 20 ms\n",
    "posy2 = d['posy2'][:,0] # y-position of right LED every 20 ms\n",
    "posy_c = d['posy_c'][:, 0] # y-position of mouse's head (middle of LEDs)\n",
    "\n",
    "box_size = d['boxSize'][0, 0]\n",
    "\n",
    "orig_T = posx.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbh3PBVIB5_G"
   },
   "source": [
    "<br><br>\n",
    "From the LED data, we can also compute the `speed` and the `head_direction` of the mouse. We do this in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XuUyuYoxB5_H"
   },
   "outputs": [],
   "source": [
    "# From LED data...\n",
    "\n",
    "# Compute speed\n",
    "velx = np.diff(posx_c); vely = np.diff(posy_c); # add the extra just to make the vectors the same size\n",
    "speed = np.sqrt(velx**2+vely**2) / bin_width;\n",
    "speed = np.append(speed, speed[-1])\n",
    "\n",
    "# Set any values over 50 cm/s to 50 cm/s\n",
    "max_speed = 50\n",
    "speed[speed > max_speed] = max_speed\n",
    "\n",
    "# Compute head direction\n",
    "head_direction = np.arctan2(posy2-posy, posx2-posx)+np.pi/2;\n",
    "head_direction[head_direction < 0] += np.pi*2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91KLq9M4B5_H"
   },
   "source": [
    "<br><br>Let's plot our data. We have the spike occurences in 20 ms bins in `spikes`, the speed values in 20 ms bins in `speed`, the head direction values in 20 ms bins in `head_direction`, and the x/y positions of the mouse in `pos_x` and `pos_y` respectively (not shown).<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DPVUsbhXB5_H"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize = (10, 5), sharex = True)\n",
    "\n",
    "t = np.arange(0, orig_T*bin_width, bin_width)\n",
    "axes[0].plot(t, spikes, 'k')\n",
    "axes[0].set(title = 'Spikes per bin')\n",
    "\n",
    "axes[1].plot(t, speed, 'k')\n",
    "axes[1].set(title = 'Speed (cm/s)')\n",
    "\n",
    "axes[2].plot(t, head_direction, 'k')\n",
    "axes[2].set(title = 'Head direction (radians)', xlabel = 'Time (s)')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9Y0Ghr8B5_I"
   },
   "source": [
    "<br><br>\n",
    "As you know, it's vital to use separate data for fitting the model and for testing its accuracy. Thus we will start by splitting our trials (time bins) into train and test subsets. We'll interleave the test chunks throughout the experiment.\n",
    "\n",
    "We're actually going to use only 30% of our data total. This is to conserve memory and model fitting time on this homework (it's a lot of data!). In real life, you'd want to use all of your data for analyses, but it's often sensible to draft code using just a portion of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lXXRJWTGB5_I"
   },
   "outputs": [],
   "source": [
    "# Use 30% of data total to conserve time/memory\n",
    "T = int(.3*orig_T)\n",
    "\n",
    "# Determine number of bins to use for test and train data\n",
    "test_T = int(.2*T)      # 20% for testing\n",
    "train_T = T - test_T    # 80% for training\n",
    "\n",
    "# Get test bin indices\n",
    "test_inds = []\n",
    "for i_chunk in range(5):\n",
    "  # in each fifth, take the first 20% for test data\n",
    "  test_inds.append(np.arange(i_chunk*T/5, i_chunk*T/5+test_T/5) )\n",
    "\n",
    "test_inds = np.concatenate(test_inds).astype('int')\n",
    "\n",
    "# Define train bin indices as non-test ones\n",
    "train_inds = np.setdiff1d(np.arange(T), test_inds)\n",
    "\n",
    "# Splice spiking data into train vs test data\n",
    "spikes_train = spikes[train_inds]\n",
    "spikes_test = spikes[test_inds]\n",
    "\n",
    "# Visualize train and test time bin assignment\n",
    "plt.plot(train_inds,np.ones(train_inds.shape)-.1,'r.')\n",
    "plt.plot(test_inds,np.ones(test_inds.shape),'b.')\n",
    "plt.ylim([0, 2])\n",
    "plt.xlabel('Time bin number')\n",
    "plt.legend(['Train', 'Test']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XuKgauISuzj"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zli92nu_B5_I"
   },
   "source": [
    "# I. Fitting an LNP model with head direction as input\n",
    "\n",
    "Like Hardcastle et al., we want to fit a Linear-Nonlinear-Poisson model to predict spikes from the behavioral data. We will first build an LNP model with head direction as the only input.\n",
    "\n",
    "Since we are using pretty big time bins (20 ms), we will use head direction during the same time bin as the stimulus to predict the neural response. In other words, we won't consider prior or future head directions, which rests on the assumption that the neuron's response latency is within 20 ms.\n",
    "\n",
    "The LN model framework isn't set up to convert a single number (head direction) to a predicted response -- we wouldn't be able to interpret much from the fitted linear filter. We will do something quite common and bin the head direction values.\n",
    "\n",
    "We'll create `hd_bins`, an array where the rows are time steps and the columns are different ranges of head direction values given by `hd_bin_edges`. The entries are 1 if the mouse's head direction was in that range of head directions at that time, 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "faFQvFmPB5_I"
   },
   "outputs": [],
   "source": [
    "# Bin head direction\n",
    "n_hd_bins = 18\n",
    "hd_bin_edges = np.linspace(0, 2*np.pi+.01, n_hd_bins + 1)\n",
    "\n",
    "hd_bins = np.zeros((T, n_hd_bins))\n",
    "\n",
    "for i_t in range(T):\n",
    "    hd_bins[i_t, :], _ = np.histogram(head_direction[i_t], bins = hd_bin_edges)\n",
    "\n",
    "# Split into train and test\n",
    "hd_bins_train = hd_bins[train_inds]\n",
    "hd_bins_test = hd_bins[test_inds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDimhlHMB5_I"
   },
   "source": [
    "## 1a (coding): Building an LNP model with head direction as input\n",
    "\n",
    "Let's build our LNP model! \n",
    "\n",
    "We'll use an exponential nonlinearity. We can write our model as:\n",
    "\n",
    "$$\n",
    "\\hat{r} = e^{X \\cdot k}\n",
    "$$\n",
    "$$\n",
    "\\hat{y} = Poiss(\\hat{r})\n",
    "$$\n",
    "\n",
    "where $X$ is a matrix in which the rows are samples/observations (different time bins) and the columns are different features of the input. In this case, each column would correspond to a different head direction bin.\n",
    "\n",
    "$k$ is the linear filter we're learning and will be a vector the same size as the number of input features.\n",
    "\n",
    "$\\hat{r}$ is the predicted underlying response.\n",
    "\n",
    "$\\hat{y}$ is a predicted spike train.\n",
    "\n",
    "<br><br>\n",
    "Complete the code below to build a forward LNP model (predicting response and spikes given the head direction and linear filter).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kDh9sE30B5_J"
   },
   "outputs": [],
   "source": [
    "def LNP_predictions(linear_filter, inputs):\n",
    "    \"\"\" Predict underlying response and spiking using LNP model\n",
    "\n",
    "    Args:\n",
    "    linear_filter: numpy array that is a vector of size (number of inputs, )\n",
    "    inputs: numpy array that is size (number of time steps, number of inputs)\n",
    "\n",
    "    Return:\n",
    "      predicted_response: numpy array of vector of size (number of time steps,)\n",
    "      predicted_spikes: numpy array of vector of size (number of time steps, )\n",
    "    \"\"\"\n",
    "    \n",
    "    # TO DO: Compute the filtered input\n",
    "    # hint: consider the desired shape of filtered_values\n",
    "    filtered_values = ...\n",
    "\n",
    "    # TO DO: Apply exponential nonlinearity\n",
    "    predicted_response = ...\n",
    "\n",
    "    # TO DO: Draw Poisson spiking from predicted response\n",
    "    # hint: https://numpy.org/doc/stable/reference/random/generated/numpy.random.poisson.html\n",
    "    predicted_spikes = ...\n",
    "    \n",
    "    return predicted_response, predicted_spikes\n",
    "\n",
    "\n",
    "# Define a placeholder head direction filter\n",
    "hd_filter = np.zeros((n_hd_bins,))\n",
    "\n",
    "# Predict response\n",
    "predicted_response, predicted_spikes = LNP_predictions(hd_filter, hd_bins_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XuKgauISuzj"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b: Checking understanding\n",
    "\n",
    "Let's pause and check our understanding. \n",
    "\n",
    "i) What is the shape of `predicted_response` and what does that correspond to? \n",
    "\n",
    "ii) First, without actually calculating it, what would be the accuracy of our model so far and why? \n",
    "\n",
    "iii) How would you determine accuracy in this case? Be specific. If you don't get an actual number for accuracy, why?\n",
    "\n",
    "_You may want to explore the variables using code._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#2AAA8A><span style=\"font-size:larger;\">\n",
    "**Answer**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XuKgauISuzj"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_-C0J2iB5_J"
   },
   "source": [
    "## 1c (coding): Calculating NLL for LNP model\n",
    "\n",
    "We have set up our LNP model, and we now want to fit this model to the data by minimizing the negative log likelihood.\n",
    "\n",
    "Complete the function below that will compute NLL for any given inputs `linear_filter`, `X`, and `spikes`.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 119,
     "status": "ok",
     "timestamp": 1739331762985,
     "user": {
      "displayName": "Kristina Penikis",
      "userId": "11146911841924357157"
     },
     "user_tz": 300
    },
    "id": "L9057wAWB5_J",
    "outputId": "cb294237-e85a-43f4-f3ac-34693dcaa160"
   },
   "outputs": [],
   "source": [
    "def compute_nll(linear_filter, X, spikes):\n",
    "\n",
    "    # Predict response given filter and inputs\n",
    "    predicted_rate, predicted_spikes = LNP_predictions(linear_filter, X)\n",
    "\n",
    "    # TO DO: Compute negative log likelihood\n",
    "    neg_log_lik = ...\n",
    "    # hint: use the formula from class 6, but be thoughtful about what variables\n",
    "    # you choose! what yields the most reliable estimate of error?)\n",
    "    \n",
    "    return neg_log_lik\n",
    "\n",
    "negative_log_likelihood = compute_nll(hd_filter, hd_bins_train, spikes_train)\n",
    "print(negative_log_likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XuKgauISuzj"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKq1BzYaB5_J"
   },
   "source": [
    "## 1d (coding): Fitting the LNP model\n",
    "\n",
    "To find the parameters that minimize a metric (in this case negative log likelihood), we can use `scipy.optimize.minimize`. To use this, we need an initial guess for the linear filter and our function that outputs the metric (`compute_nll`). The initial guess doesn't really matter for now (just guess all zeros or ones), it just needs to be the right size and shape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1999,
     "status": "ok",
     "timestamp": 1739331766631,
     "user": {
      "displayName": "Kristina Penikis",
      "userId": "11146911841924357157"
     },
     "user_tz": 300
    },
    "id": "AfjbO3gOB5_K",
    "outputId": "8cd8ec0c-60cf-4147-ff40-df1da82406b0"
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# TO DO: Initial guess of linear filter\n",
    "init_guess = ...\n",
    "\n",
    "# Fit model\n",
    "result = minimize(compute_nll, init_guess, args=(hd_bins_train, spikes_train), method=\"Powell\")\n",
    "\n",
    "print(result)\n",
    "linear_filter = result['x']\n",
    "NLL_H = result['fun']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXpWn8zfB5_K"
   },
   "source": [
    "<br><br>\n",
    "**Let's visualize the fitted linear filter!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bsZXwkyfB5_K"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(hd_bin_edges[:-1], linear_filter, 'k')\n",
    "ax.set(xlabel = 'Head direction (radians)');\n",
    "\n",
    "# Your output should look like the plot in \"HW3-P1d_HD-filter.png\" found in the HW3 folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XuKgauISuzj"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlvnH8CQB5_K"
   },
   "source": [
    "## 1e: Intepreting the linear filter\n",
    "\n",
    "i) What head direction of the mouse results in the highest neural response? What would we expect to see if the neuron wasn't influenced at all by the head direction of the mouse?\n",
    "\n",
    "ii) Can you tell how much the neuron's response is affected by head direction from looking at this filter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKKiTdDffUfy"
   },
   "source": [
    "<font color=#2AAA8A><span style=\"font-size:larger;\">\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZzoF0jUB5_L"
   },
   "source": [
    "## 1f: Assessing model performance (coding)\n",
    "\n",
    "To determine how much the neural responses are affected by head direction, we need to compute a metric of how good the model is -- how much of the variance in neural responses the model can explain. \n",
    "\n",
    "Remember, we don't want to assess the performance on the model based on the training data, but now want to use the data we set aside for testing the model.\n",
    "\n",
    "Using the test data:\n",
    "\n",
    "i) Predict the underlying response and spikes using your fitted LNP model.\n",
    "\n",
    "ii) Modify the plotting code to show the predicted spikes on the second subplot, to compare with the true spikes.\n",
    "\n",
    "iii) Compute the correlation coefficient between the predicted response and the true spikes. This is a common way to assess goodness of spiking predictions. A correlation coefficient of 0 means there is no correlation; the model is predicting spikes at chance levels. A correlation coefficient of 1 is perfect prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mlFLmZ93B5_L"
   },
   "outputs": [],
   "source": [
    "# i) TO DO: Predict underlying response and spikes\n",
    "predicted_response, predicted_spikes = ...\n",
    "\n",
    "# Visualize predictions vs real data\n",
    "fig, axes = plt.subplots(2, 1)\n",
    "axes[0].eventplot(np.where(spikes_test)[0], colors='k')\n",
    "axes[0].set(title = 'True Spikes')\n",
    "\n",
    "# ii) TO DO: add subplot to display predicted spikes\n",
    "...\n",
    "axes[1].set(title = 'Predicted Spikes')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iii) TODO: Compute the correlation coefficient between true and predicted responses on test data. \n",
    "#      Recall, above, when you considered which variables provide a stable estimate of accuracy. \n",
    "corr_coef = ...\n",
    "print(f'The correlation coefficient is {corr_coef}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tTfizCxxB5_L"
   },
   "source": [
    "## 1g: Interpret the result (conceptual)\n",
    "\n",
    "Does it seem like the neuron is very driven by head direction? Are the neural responses explained well by what head direction the mouse is facing? Explain your thinking.\n",
    "\n",
    "<font color=#2AAA8A><span style=\"font-size:larger;\">\n",
    "**Answer**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpl7lAgrB5_L"
   },
   "source": [
    "# II. Predicting response using multiple variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F92pify3B5_M"
   },
   "source": [
    "**Fitting the LNP to head direction *and* running speed**\n",
    "\n",
    "We now want to predict the neural response as a function of both speed and head direction during each time bin.\n",
    "\n",
    "Like for head direction, we will group speed values into bins. In the cell below, the array `speed_bins` has rows corresponding to time bins and columns corresponding to different speed ranges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VMX13x1SB5_M"
   },
   "outputs": [],
   "source": [
    "# Determine the number of bins\n",
    "n_speed_bins = 10\n",
    "\n",
    "# Get bin edges\n",
    "max_speed = np.max(speed)\n",
    "speed_bin_edges = np.linspace(0, max_speed, n_speed_bins + 1)\n",
    "\n",
    "# Bin speed values\n",
    "speed_bins = np.zeros((T, n_speed_bins))\n",
    "for i_t in range(T):\n",
    "    speed_bins[i_t, :], _ = np.histogram(speed[i_t], bins = speed_bin_edges)\n",
    "\n",
    "# Splice data into test vs train\n",
    "speed_bins_train = speed_bins[train_inds]\n",
    "speed_bins_test = speed_bins[test_inds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zK4iyjshB5_M"
   },
   "source": [
    "## 1h: Fitting an LNP model to both speed and head direction (coding)\n",
    "\n",
    "Complete the code below to fit an LNP model to both speed and head direction.\n",
    "\n",
    "Hints:\n",
    "* You should change your input and initial guess but use the same functions you've already made.\n",
    "* The input data is always structured as an array of [samples x features]. To use information from two variables in the input data, you will include additional features for each sample (time bin)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: complete code\n",
    "\n",
    "# Make training and testing input data, including both speed and head direction\n",
    "inputs_train = ...\n",
    "inputs_test = ...\n",
    "\n",
    "# Initial guess of linear filter\n",
    "init_guess = ...\n",
    "\n",
    "# Fit model\n",
    "result = minimize(compute_nll, init_guess, args=(inputs_train, spikes_train), method=\"Powell\")\n",
    "print(result)\n",
    "linear_filter = ...\n",
    "\n",
    "# Get filters for speed and head direction\n",
    "# hint: The linear filter contains coefficients for speed bins followed by head direction bins\n",
    "speed_filter = ...\n",
    "hd_filter = ...\n",
    "\n",
    "\n",
    "# Visualize filters - separate out speed from head direction filters\n",
    "fig, axes = plt.subplots(1, 2, figsize = (10, 5))\n",
    "\n",
    "axes[0].plot(speed_bin_edges[:-1], speed_filter, 'k')\n",
    "axes[0].set(xlabel = 'Speed (cm/s)');\n",
    "\n",
    "axes[1].plot(hd_bin_edges[:-1], hd_filter, 'k')\n",
    "axes[1].set(xlabel = 'Head direction (radians)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8rA7rOYB5_M"
   },
   "source": [
    "## 1i: Assessing model performance (conceptual)\n",
    "\n",
    "How good are the predictions when we used both head direction and speed as inputs to the model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1739328412313,
     "user": {
      "displayName": "Kristina Penikis",
      "userId": "11146911841924357157"
     },
     "user_tz": 300
    },
    "id": "f9uP2sYBB5_M",
    "outputId": "5d70a189-fd49-43ae-97c3-7e782adad167"
   },
   "outputs": [],
   "source": [
    "# Predict response and spikes\n",
    "predicted_response, predicted_spikes = LNP_predictions(linear_filter, inputs_test)\n",
    "\n",
    "# Compute the correlation coefficient between true and predicted response on test data\n",
    "corr_coef = np.corrcoef(predicted_response, spikes_test)[0, 1]\n",
    "print(f'The correlation coefficient is {corr_coef}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4Hk2w6bB5_M"
   },
   "source": [
    "<br>**Would you classify this neuron as singly selective to head direction or as having mixed selectivity to head direction and speed? Explain your answer.**\n",
    "<br> To rigorously determine the answer, we should perform a deeper statistical comparison. For the purpose of the assignment, make a cursory assessment using the results you've already computed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3QT-YZQJEeLS"
   },
   "source": [
    "<font color=#2AAA8A><span style=\"font-size:larger;\">\n",
    "**Answer**\n",
    "\n",
    "<font color=#2AAA8A>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUofHBTfh06m"
   },
   "source": [
    "# III. Incorporating position as an input\n",
    "\n",
    "It turns out that this particular neuron is actually affected a lot by position. In other words, the LNP's prediction of spiking responses is better if we include position as an input.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1j. Using position as an input to the LNP (coding)\n",
    "\n",
    "**Write code to determine how this neuron's spiking is affected by position. What is the prediction accuracy with position alone, and with position + head direction?**\n",
    "\n",
    "Note there is an additional consideration in setting up the filter for the position of the mouse. The position inputs should reflect the combined x,y position of the mouse instead of the x pos and y pos separately. If you look at a grid cell's RF, it's clear that neurons are selective for a location in space, i.e. a certain *combination* of x and y. Therefore, we want to bin position data within the whole grid. If you choose 10 bins for each of the x and y dimensions, then you'd have 100 bins total (instead of 20).\n",
    "\n",
    "Overall, this question will be more of a challenge. Take it step by step, and recycle code from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, compute position histogram, linking x and y positions\n",
    "nposbins = 10  # in each x and y dimensions\n",
    "pos = np.column_stack((posx_c, posy_c))\n",
    "posbins = np.arange(box_size/nposbins/2, box_size, box_size/nposbins)\n",
    "posgrid = np.zeros((T, nposbins**2))\n",
    "\n",
    "for i_t in range(T):\n",
    "    xcoor = np.argmin(np.abs(pos[i_t,0]-posbins))\n",
    "    ycoor = np.argmin(np.abs(pos[i_t,1]-posbins))\n",
    "    bin_idx = np.ravel_multi_index(([nposbins - ycoor - 1], [xcoor]), (nposbins, nposbins))\n",
    "    posgrid[i_t, bin_idx] = 1\n",
    "    \n",
    "print(\"posgrid shape is \"+ str(np.shape(posgrid)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Your code here! Feel free to break this up into separate cells.\n",
    "\n",
    "# Splice data into test vs train\n",
    "pos_train = ...\n",
    "pos_test = ...\n",
    "\n",
    "print(\"pos_train shape is \"+ str(np.shape(pos_train)))\n",
    "\n",
    "\n",
    "# Fit model \n",
    "\n",
    "\n",
    "# Plot position filter in 1d and in 2d. Neither will be immediately interpretable, but read on.\n",
    "position_filter = ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The resulting position filter should look like this:\n",
    "position_filter_key = np.load('pos_filter.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why does the filter look so weird? \n",
    "# The mouse does not travel to every position in the grid within this\n",
    "# subset of the experimental data. This results in the highly negative\n",
    "# values you see in the filter above. These artifacts don't impact the\n",
    "# prediction accuracy much in this case, but it makes it impossible to visualize\n",
    "# any structure in the filter. There are a few ways we can correct for this,\n",
    "# including making fewer/larger position bins, or setting the filter values for\n",
    "# the missing positions to the median filter value.\n",
    "position_filter_key[position_filter_key < -70] = np.median(position_filter_key[position_filter_key > -70])\n",
    "\n",
    "\n",
    "# Plot linear filter for position in 1d (still doesn't make much sense)\n",
    "binvecidx = np.arange(0,len(position_filter_key))\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(binvecidx, position_filter_key, 'k')\n",
    "ax.set(xlabel = 'pos grid bins');\n",
    "\n",
    "# Plot linear filter in 2d (see a little more structure)\n",
    "linearfilter_posgrid = np.reshape(position_filter_key, (nposbins, nposbins))\n",
    "fig, ax = plt.subplots()\n",
    "cax = ax.imshow(linearfilter_posgrid, cmap='gray')\n",
    "fig.colorbar(cax)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use `position_filter_key` as your linear filter for the next cell if you couldn't get your filter to match it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use position_filter_key as your linear filter for this cell.\n",
    "\n",
    "# Test model\n",
    "...\n",
    "corr_coef_pos = ...\n",
    "print(f'The correlation coefficient using position information only is {corr_coef_pos}.')\n",
    "\n",
    "\n",
    "# ~~~~~~ Comments on position-only result ~~~~~~\n",
    "#\n",
    "# Model performance is substantially better (.178) but still not great.\n",
    "# It gets much better when more of the data is used.\n",
    "# By using only 30% of the data, many of the position bins are visited only\n",
    "# a few times and this contributes to relatively poor model accuracy.\n",
    "#\n",
    "# We can fudge having more data by increasing the size of the position bins.\n",
    "# The caveat is that the bins have to be small enough to capture the positional\n",
    "# tuning width of the cell (ie. the grid cell's hotspots can't be closer\n",
    "# together than the bins can capture).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "####     Now, fit a model to position AND head direction    ####\n",
    "################################################################\n",
    "# (forget about speed because it doesn't contribute to this cell)\n",
    "# Note: it may take a little longer to fit the model this time (up to 10s).\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "corr_coef_pos_hd = ...\n",
    "print(f'The correlation coefficient using position and head direction is {corr_coef_pos_hd}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~~~~ Interpreting the result ~~~~~~\n",
    "#\n",
    "# Including both head direction and position increases model performance to 0.197, \n",
    "# the highest correlation we've yet observed. This may not seem impressive, but it \n",
    "# corresponds to the range of performances observed by Hardcastle. \n",
    "#   -> See the middle histogram in Fig. S3a (code below will open an image). \n",
    "# Note that in the paper they also added a smoothing step before calculating the \n",
    "# correlation coefficient, which would slightly improve performance.\n",
    "\n",
    "from PIL import Image\n",
    "img = Image.open('Hardcastle_FigS3a.png')\n",
    "img.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrQLEzxTfZ9h"
   },
   "source": [
    "# IV. Alternative methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLWz9dJLB5_M"
   },
   "source": [
    "## 1k: Using the LNP vs. tuning curves (conceptual)\n",
    "\n",
    "Why are tuning curves insufficient to determine if neurons have mixed selectivity? What, specifically, can you learn from the present approach that you could not by plotting tuning curves for each stimulus property?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBEBYXLdfFZ5"
   },
   "source": [
    "<font color=#2AAA8A><span style=\"font-size:larger;\">\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wScLcQyUihc7"
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
